{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import math\n",
    "from copy import deepcopy\n",
    "from collections import Counter\n",
    "from io import StringIO\n",
    "from operator import itemgetter, attrgetter\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn import tree\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import pydot_ng as pydot\n",
    "from IPython.display import Image\n",
    "from tabulate import tabulate\n",
    "\n",
    "from ipywidgets import IntProgress\n",
    "from IPython.display import display\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('./speed-dating-experiment/Speed Dating Data.csv', encoding=\"ISO-8859-1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyze Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 8378 entries, 0 to 8377\n",
      "Columns: 195 entries, iid to amb5_3\n",
      "dtypes: float64(174), int64(13), object(8)\n",
      "memory usage: 12.5+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['field', 'undergra', 'mn_sat', 'tuition', 'from', 'zipcode', 'income',\n",
       "       'career'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Unparseable columns\n",
    "\n",
    "unparseable_cols = df.select_dtypes(include=['object']).columns\n",
    "unparseable_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "num_in_3    7710\n",
       "numdat_3    6882\n",
       "expnum      6578\n",
       "sinc7_2     6423\n",
       "amb7_2      6423\n",
       "shar7_2     6404\n",
       "intel7_2    6394\n",
       "fun7_2      6394\n",
       "attr7_2     6394\n",
       "amb5_3      6362\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Number of null value of each columns\n",
    "\n",
    "cols_to_null_nums = df.isnull().sum(axis=0).sort_values(ascending=False)\n",
    "cols_to_null_nums[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "842    172\n",
       "847    172\n",
       "845    172\n",
       "839    172\n",
       "843    172\n",
       "838    171\n",
       "324    158\n",
       "841    155\n",
       "846    154\n",
       "840    154\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Number of null value of each row\n",
    "\n",
    "rows_to_null_nums = df.isnull().sum(axis=1).sort_values(ascending=False)\n",
    "rows_to_null_nums[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nacat/anaconda3/lib/python3.5/site-packages/numpy/lib/function_base.py:3834: RuntimeWarning: Invalid value encountered in percentile\n",
      "  RuntimeWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>iid</th>\n",
       "      <th>id</th>\n",
       "      <th>gender</th>\n",
       "      <th>idg</th>\n",
       "      <th>condtn</th>\n",
       "      <th>wave</th>\n",
       "      <th>round</th>\n",
       "      <th>position</th>\n",
       "      <th>positin1</th>\n",
       "      <th>order</th>\n",
       "      <th>...</th>\n",
       "      <th>attr3_3</th>\n",
       "      <th>sinc3_3</th>\n",
       "      <th>intel3_3</th>\n",
       "      <th>fun3_3</th>\n",
       "      <th>amb3_3</th>\n",
       "      <th>attr5_3</th>\n",
       "      <th>sinc5_3</th>\n",
       "      <th>intel5_3</th>\n",
       "      <th>fun5_3</th>\n",
       "      <th>amb5_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>8378.000000</td>\n",
       "      <td>8377.000000</td>\n",
       "      <td>8378.000000</td>\n",
       "      <td>8378.000000</td>\n",
       "      <td>8378.000000</td>\n",
       "      <td>8378.000000</td>\n",
       "      <td>8378.000000</td>\n",
       "      <td>8378.000000</td>\n",
       "      <td>6532.000000</td>\n",
       "      <td>8378.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>3974.000000</td>\n",
       "      <td>3974.000000</td>\n",
       "      <td>3974.000000</td>\n",
       "      <td>3974.000000</td>\n",
       "      <td>3974.000000</td>\n",
       "      <td>2016.000000</td>\n",
       "      <td>2016.000000</td>\n",
       "      <td>2016.000000</td>\n",
       "      <td>2016.000000</td>\n",
       "      <td>2016.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>283.675937</td>\n",
       "      <td>8.960248</td>\n",
       "      <td>0.500597</td>\n",
       "      <td>17.327166</td>\n",
       "      <td>1.828837</td>\n",
       "      <td>11.350919</td>\n",
       "      <td>16.872046</td>\n",
       "      <td>9.042731</td>\n",
       "      <td>9.295775</td>\n",
       "      <td>8.927668</td>\n",
       "      <td>...</td>\n",
       "      <td>7.240312</td>\n",
       "      <td>8.093357</td>\n",
       "      <td>8.388777</td>\n",
       "      <td>7.658782</td>\n",
       "      <td>7.391545</td>\n",
       "      <td>6.810020</td>\n",
       "      <td>7.615079</td>\n",
       "      <td>7.932540</td>\n",
       "      <td>7.155258</td>\n",
       "      <td>7.048611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>158.583367</td>\n",
       "      <td>5.491329</td>\n",
       "      <td>0.500029</td>\n",
       "      <td>10.940735</td>\n",
       "      <td>0.376673</td>\n",
       "      <td>5.995903</td>\n",
       "      <td>4.358458</td>\n",
       "      <td>5.514939</td>\n",
       "      <td>5.650199</td>\n",
       "      <td>5.477009</td>\n",
       "      <td>...</td>\n",
       "      <td>1.576596</td>\n",
       "      <td>1.610309</td>\n",
       "      <td>1.459094</td>\n",
       "      <td>1.744670</td>\n",
       "      <td>1.961417</td>\n",
       "      <td>1.507341</td>\n",
       "      <td>1.504551</td>\n",
       "      <td>1.340868</td>\n",
       "      <td>1.672787</td>\n",
       "      <td>1.717988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>154.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>281.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>407.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>552.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>44.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 187 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               iid           id       gender          idg       condtn  \\\n",
       "count  8378.000000  8377.000000  8378.000000  8378.000000  8378.000000   \n",
       "mean    283.675937     8.960248     0.500597    17.327166     1.828837   \n",
       "std     158.583367     5.491329     0.500029    10.940735     0.376673   \n",
       "min       1.000000     1.000000     0.000000     1.000000     1.000000   \n",
       "25%     154.000000          NaN     0.000000     8.000000     2.000000   \n",
       "50%     281.000000          NaN     1.000000    16.000000     2.000000   \n",
       "75%     407.000000          NaN     1.000000    26.000000     2.000000   \n",
       "max     552.000000    22.000000     1.000000    44.000000     2.000000   \n",
       "\n",
       "              wave        round     position     positin1        order  \\\n",
       "count  8378.000000  8378.000000  8378.000000  6532.000000  8378.000000   \n",
       "mean     11.350919    16.872046     9.042731     9.295775     8.927668   \n",
       "std       5.995903     4.358458     5.514939     5.650199     5.477009   \n",
       "min       1.000000     5.000000     1.000000     1.000000     1.000000   \n",
       "25%       7.000000    14.000000     4.000000          NaN     4.000000   \n",
       "50%      11.000000    18.000000     8.000000          NaN     8.000000   \n",
       "75%      15.000000    20.000000    13.000000          NaN    13.000000   \n",
       "max      21.000000    22.000000    22.000000    22.000000    22.000000   \n",
       "\n",
       "          ...           attr3_3      sinc3_3     intel3_3       fun3_3  \\\n",
       "count     ...       3974.000000  3974.000000  3974.000000  3974.000000   \n",
       "mean      ...          7.240312     8.093357     8.388777     7.658782   \n",
       "std       ...          1.576596     1.610309     1.459094     1.744670   \n",
       "min       ...          2.000000     2.000000     3.000000     2.000000   \n",
       "25%       ...               NaN          NaN          NaN          NaN   \n",
       "50%       ...               NaN          NaN          NaN          NaN   \n",
       "75%       ...               NaN          NaN          NaN          NaN   \n",
       "max       ...         12.000000    12.000000    12.000000    12.000000   \n",
       "\n",
       "            amb3_3      attr5_3      sinc5_3     intel5_3       fun5_3  \\\n",
       "count  3974.000000  2016.000000  2016.000000  2016.000000  2016.000000   \n",
       "mean      7.391545     6.810020     7.615079     7.932540     7.155258   \n",
       "std       1.961417     1.507341     1.504551     1.340868     1.672787   \n",
       "min       1.000000     2.000000     2.000000     4.000000     1.000000   \n",
       "25%            NaN          NaN          NaN          NaN          NaN   \n",
       "50%            NaN          NaN          NaN          NaN          NaN   \n",
       "75%            NaN          NaN          NaN          NaN          NaN   \n",
       "max      12.000000    10.000000    10.000000    10.000000    10.000000   \n",
       "\n",
       "            amb5_3  \n",
       "count  2016.000000  \n",
       "mean      7.048611  \n",
       "std       1.717988  \n",
       "min       1.000000  \n",
       "25%            NaN  \n",
       "50%            NaN  \n",
       "75%            NaN  \n",
       "max      10.000000  \n",
       "\n",
       "[8 rows x 187 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Clean Comma\n",
    "COLUMNS_WITH_COMMA = ['income', 'zipcode', 'tuition', 'mn_sat']\n",
    "\n",
    "for col in COLUMNS_WITH_COMMA:\n",
    "    df[col] = df[col].replace('[,]', '', regex=True).astype(float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handle String Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ENCODED_STRING_COLUMNS = ['career', 'field']\n",
    "df.drop(ENCODED_STRING_COLUMNS, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "OTHER_STRING_COLUMNS = ['undergra', 'from']\n",
    "\n",
    "# Joined df based on partner\n",
    "joined_df = df.merge(\n",
    "    df,\n",
    "    how='left',\n",
    "    left_on=['iid', 'id', 'pid', 'partner'],\n",
    "    right_on=['pid', 'partner', 'iid', 'id']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df['same_from'] = joined_df['from_x'] == joined_df['from_y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df['same_undergra'] = joined_df['undergra_x'] == joined_df['undergra_y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.drop(OTHER_STRING_COLUMNS, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Method Implementation\n",
    "\n",
    "## KNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Self Implement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def eucldn_similarity(v1, v2):\n",
    "    \"\"\"\n",
    "    Euclidean Distance。越相似，距離越近，相似度數值會越小。\n",
    "    :param v1:\n",
    "    :param v2:\n",
    "    :return: 1/distance(v1,v2) 取距離的倒數，越大越像\n",
    "    \"\"\"\n",
    "    sum_xx, sum_xy, sum_yy = 0.0, 0.0, 0.0\n",
    "    for item1, item2 in zip(v1, v2):\n",
    "        sum_xx += math.pow(item1, 2)\n",
    "        sum_xy += item1*item2\n",
    "        sum_yy += math.pow(item2, 2)\n",
    "    return 1 / math.sqrt(sum_xx + sum_yy - 2*sum_xy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def cos_similarity(v1, v2):\n",
    "    \"\"\"\n",
    "    Cosine（兩向量的餘弦）。越相似，夾角越小，相似度數值會越高。\n",
    "    :param v1:\n",
    "    :param v2:\n",
    "    :return: cos(v1,v2)介於1到-1之間 越大越像\n",
    "    \"\"\"\n",
    "    sum_xx, sum_xy, sum_yy = 0.0, 0.0, 0.0\n",
    "    for item1, item2 in zip(v1, v2):\n",
    "        sum_xx += math.pow(item1, 2)\n",
    "        sum_xy += item1*item2\n",
    "        sum_yy += math.pow(item2, 2)\n",
    "    return sum_xy / math.sqrt(sum_xx*sum_yy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def knn_prediction(nb_list):\n",
    "    cnt = Counter(target for (sim, target) in nb_list)\n",
    "    label = cnt.most_common(1)[0][0]\n",
    "    return label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def knn_classify(test_X, train_X, train_y, k=5):\n",
    "    nb = []\n",
    "    for feature, label in zip(train_X, train_y):\n",
    "        nb.append((cos_similarity(test_X,feature),tuple(label)))\n",
    "    nb.sort(reverse=True)\n",
    "    label = knn_prediction(nb[:k])\n",
    "    return label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def knn(train_X, test_X, train_y, test_y, n_neighbors=5):\n",
    "    count = 0\n",
    "    for feature, label in zip(test_X, test_y):\n",
    "        pred_y = knn_classify(feature, train_X, train_y, n_neighbors)\n",
    "        if pred_y == tuple(label):\n",
    "            count += 1\n",
    "    accuracy = count / len(test_X)\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def knn_with_sklearn(train_X, test_X, train_y, test_y,\n",
    "                     n_neighbors=5):\n",
    "    clf = KNeighborsClassifier(n_neighbors=n_neighbors)\n",
    "    clf.fit(train_X, train_y)\n",
    "    pred = clf.predict(test_X)\n",
    "    return accuracy_score(pred, test_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Self Implement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gini_index(lcnt, rcnt):\n",
    "    gini = 0.0\n",
    "    tcnt = lcnt + rcnt\n",
    "    tl = sum(lcnt.values())\n",
    "    tr = sum(rcnt.values())\n",
    "    tt = tl + tr\n",
    "    l = 0.0\n",
    "    r = 0.0\n",
    "    for class_label in set(tcnt):\n",
    "        if tl is not 0:\n",
    "            l += pow(lcnt[class_label]/tl,2)\n",
    "        if tr is not 0:    \n",
    "            r += pow(rcnt[class_label]/tr,2)\n",
    "    if tt is not 0:\n",
    "        gini = (tl/tt)*(1-l)+(tr/tt)*(1-r)\n",
    "    return gini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def try_split(train_X, train_y, index, value):\n",
    "    gini = 1.0\n",
    "    left_X, right_X = list(), list()\n",
    "    left_y, right_y = list(), list()\n",
    "    lcnt, rcnt, tcnt = Counter(), Counter(), Counter\n",
    "    for row_X, row_y in zip(train_X, train_y):\n",
    "        if row_X[index] < value:\n",
    "            left_X.append(row_X)\n",
    "            left_y.append(row_y)\n",
    "            lcnt[tuple(row_y)] += 1\n",
    "        else:\n",
    "            right_X.append(row_X)\n",
    "            right_y.append(row_y)\n",
    "            rcnt[tuple(row_y)] += 1\n",
    "    if not left_X:\n",
    "        l = 0\n",
    "    else:\n",
    "        l = lcnt.most_common(1)[0][0]\n",
    "    if not right_X:\n",
    "        r = 0\n",
    "    else:\n",
    "        r = rcnt.most_common(1)[0][0]\n",
    "    gini = gini_index(lcnt, rcnt)\n",
    "    return gini, left_X, right_X, left_y, right_y, l, r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def determine_split(train_X, train_y):\n",
    "    b_feature, b_value, b_gini, b_group = 999, 999, 999, None\n",
    "    for index in range(len(train_X[0])):\n",
    "        for tp in train_X:\n",
    "            gini, left_group, right_group, left_label, right_label, l, f= try_split(train_X, train_y, index, tp[index])\n",
    "            groups = left_group, right_group\n",
    "            labels = left_label, right_label\n",
    "            counter = l, f\n",
    "            if gini < b_gini:\n",
    "                b_index, b_value, b_gini, b_group, b_label, b_cnt= index, tp[index], gini, groups, labels, counter\n",
    "    return {'index':b_index, 'value':b_value, 'gini':b_gini, 'groups':b_group, 'labels':b_label, 'count':b_cnt}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def split(node, max_depth, min_size, depth):\n",
    "    left, right = node['groups']\n",
    "    l_label, r_label = node['labels']\n",
    "    l_cnt, r_cnt = node['count']\n",
    "    #del(node['groups'])\n",
    "    #del(node['labels'])\n",
    "\n",
    "    if not left or not right:\n",
    "        if isinstance(l_cnt, tuple):\n",
    "            node['left'] = node['right'] = l_cnt\n",
    "        elif isinstance(r_cnt, tuple):\n",
    "            node['left'] = node['right'] = r_cnt\n",
    "        else:\n",
    "            node['left'] = node['right'] = None\n",
    "        #node['left'] = node['right'] = countLabel(l_label+r_label)\n",
    "        return\n",
    "    if depth >= max_depth:\n",
    "        node['left'], node['right'] = l_cnt, r_cnt#countLabel(l_label), countLabel(r_label)\n",
    "        return\n",
    "    if len(left) <= min_size:\n",
    "        node['left'] = l_cnt#countLabel(l_label)\n",
    "    else:\n",
    "        node['left'] = determine_split(left, l_label)\n",
    "        split(node['left'], max_depth, min_size, depth+1)\n",
    "    if len(right) <= min_size:\n",
    "        node['right'] = r_cnt#countLabel(r_label)\n",
    "    else:\n",
    "        node['right'] = determine_split(right, r_label)\n",
    "        split(node['right'], max_depth, min_size, depth+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_tree(train_X, train_y, max_depth, min_size):\n",
    "    root = determine_split(train_X, train_y)\n",
    "    split(root, max_depth, min_size, 1)\n",
    "    return root"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def print_tree(node, depth=0):\n",
    "    if isinstance(node, dict):\n",
    "        print('%s[X%d < %.3f]' % ((depth*' ', (node['index']+1), node['value'])))\n",
    "        print_tree(node['left'], depth+1)\n",
    "        print_tree(node['right'], depth+1)\n",
    "    else:\n",
    "        print('%s[%s]' % ((depth*' ', node)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def dt_predict(tp, node):\n",
    "    if tp[node['index']] < node['value']:\n",
    "        if isinstance(node['left'], dict):\n",
    "            return dt_predict(tp, node['left'])\n",
    "        else:\n",
    "            return node['left']\n",
    "    else:\n",
    "        if isinstance(node['right'], dict):\n",
    "            return dt_predict(tp, node['right'])\n",
    "        else:\n",
    "            return node['right']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def dt_accuracy(test_X, test_y, tree):\n",
    "    accuracy = 0\n",
    "    count = 0\n",
    "    for tp, label in zip(test_X, test_y):\n",
    "        pred = dt_predict(tp, tree)\n",
    "        if pred == tuple(label):\n",
    "            count += 1\n",
    "    accuracy = count/len(test_y)\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def dt(train_X, test_X, train_y, test_y, max_depth=5, min_samples_leaf=5):\n",
    "    accuracy = 0\n",
    "    tree = build_tree(train_X, train_y, max_depth, min_samples_leaf)\n",
    "    print_tree(tree)\n",
    "    accuracy = dt_accuracy(test_X, test_y, tree)\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def dt_with_sklearn(train_X, test_X, train_y, test_y,\n",
    "                    min_samples_leaf=5):\n",
    "    clf = tree.DecisionTreeClassifier(min_samples_leaf=min_samples_leaf)\n",
    "    clf.fit(train_X, train_y)\n",
    "    pred = clf.predict(test_X)\n",
    "    return accuracy_score(pred, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Visualize Decision Tree\n",
    "\n",
    "# dot_data = StringIO()\n",
    "# tree.export_graphviz(clf, out_file=dot_data,\n",
    "#                      feature_names=df_X.columns, class_names=True)\n",
    "# graph = pydot.graph_from_dot_data(dot_data.getvalue())  \n",
    "# Image(graph.create_png())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split Data Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "LABELS = ['dec', 'dec_o']\n",
    "REDUDANT_COLUMNS = ['match']\n",
    "\n",
    "\n",
    "def split_df(df,\n",
    "             default_na=0, test_size=0.2, random_state=1):\n",
    "    df = df.fillna(default_na).drop(REDUDANT_COLUMNS, axis=1)\n",
    "    \n",
    "    df_X = df.drop(LABELS, axis=1)\n",
    "    df_y = df[LABELS]\n",
    "    \n",
    "    X, y = np.array(df_X), np.array(df_y)\n",
    "    return train_test_split(X, y,\n",
    "                            test_size=test_size, random_state=random_state)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_with_all_methods(df):\n",
    "    data = split_df(df)\n",
    "    print('Sklearn KNN Accurary: ', knn_with_sklearn(*data))\n",
    "    print('Sklearn DT Accurary: ', dt_with_sklearn(*data))\n",
    "    print('KNN Accurary: ', knn(*data))\n",
    "    print('DT Accurary: ', dt(*data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "baseline_df = deepcopy(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_with_all_methods(baseline_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Drop columns or rows with too many null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_drop_nan = deepcopy(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Drop Rows\n",
    "\n",
    "ROW_THREASHOLD = 100\n",
    "\n",
    "df_drop_nan.dropna(axis=0, thresh=ROW_THREASHOLD, inplace=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Drop Cols\n",
    "\n",
    "COL_THREASHOLD = 4000\n",
    "\n",
    "df_drop_nan.dropna(axis=1, thresh=COL_THREASHOLD, inplace=True);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_with_all_methods(df_drop_nan)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hobby Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_hs = deepcopy(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "HOBBY_COLUMNS = [\n",
    "    'sports', 'tvsports', 'exercise', 'dining', 'museums', 'art',\n",
    "    'hiking', 'gaming', 'clubbing', 'reading', 'tv', 'theater',\n",
    "    'movies', 'concerts', 'music', 'shopping', 'yoga'\n",
    "]\n",
    "\n",
    "similiar_thres = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def count_hobby_similarity(joined_df,\n",
    "                           similiar_thres=1,\n",
    "                           na_default=-1):\n",
    "    joined_df_no_na = joined_df.fillna(na_default)\n",
    "    ss = list()\n",
    "    for hobby in HOBBY_COLUMNS:\n",
    "        temp_s = abs(joined_df_no_na[hobby+'_x'] - joined_df_no_na[hobby+'_y'])\n",
    "        temp_s = (temp_s <= similiar_thres).astype(int)\n",
    "        ss.append(temp_s)\n",
    "    return sum(ss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_hs['sim_hob_num'] = count_hobby_similarity(joined_df, similiar_thres=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_hs.drop(HOBBY_COLUMNS, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_with_all_methods(df_hs)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
